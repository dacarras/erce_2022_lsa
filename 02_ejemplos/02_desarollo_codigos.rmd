---
title: 'LLECE: Taller de Análisis II'
subtitle: "Desarollo"
author: "dacarras"
date: 'Marzo 2 de 2022'
output:
  github_document:
  html_document:
    theme: paper
    highlight: kate
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
    fig_width: 10 
    fig_height: 8 
---

<style>
  .main-container {
    max-width: 1600px !important;
  }
  .list-group-item.active, 
  .list-group-item.active:focus, 
  .list-group-item.active:hover {
    background-color: #373334;
  }
</style>


```{r setup, include=FALSE}
#----------------------------------------------------------
# setup
#----------------------------------------------------------


# knitr option
knitr::opts_chunk$set(dev = 'png')
options(knitr.kable.NA = '', digits = 2)
options(scipen = 999999)

# remove all previous objects
rm(list = ls())

# fonts
Sys.setenv(LANG="en_US.UTF-8")


# ------------------------------------------------------
# get times
# ------------------------------------------------------

start_time <- Sys.time()

# ------------------------------------------------------
# cargar librerias principales
# ------------------------------------------------------

library(dplyr)


```

# Librerias a instalar

```{r echo = TRUE, eval = FALSE}

# -------------------------------------------------------------------
# librerias
# -------------------------------------------------------------------

# Nota: instalar librerias manualmente.

#------------------------------------------------
# librerias para instalar librerias remotas
#------------------------------------------------

install.packages('devtools')
install.packages('remotes')

#------------------------------------------------
# libreria ERCE con datos
#------------------------------------------------

# algunos computadores requieren esta opcion, cuando tienen instalado git
credentials::set_github_pat()

# la presente libreria se encuentra en desarollado y no es de acceso libre
devtools::install_github(
  'dacarras/erce',
  auth_token = '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',
  force = TRUE)

#------------------------------------------------
# librerías en uso
#------------------------------------------------

install.packages('tidyverse')
install.packages('mitools')
install.packages('survey')
install.packages('srvyr')


```


# Codigo 1.1: abrir los datos


- El primer problema a resolver, consiste en como **abrir los datos** que queremos emplear.

  - Algunos estudios de gran escala como ICCS 2016 por ejemplo, proveen de un archivo de datos por país, y por instrumento.

  - En cambio, otros estudios de gran escala proveen de un solo archivo para todos los países, integrando puntajes y respuestas a los cuestionarios de contexto. Este es el caso de PISA 2018.

  - **ERCE 2019** pertenece a este segundo grupo, y los datos se encuentran separados por población de estudiantes (Tercer y Sexto grado), y por instrumento o cuestionario de contexto.


```{r echo=TRUE, eval=TRUE, messages = FALSE}

# forma rápida de abrir los datos
erce_a6 <- erce::erce_2019_qa6

```



```{r echo=TRUE, eval=FALSE, messages = FALSE}
# Listado de archivos

# Base de datos de estudiantes   | # Base de datos de familias
# ERCE_2019_QA3.rds              | # ERCE_2019_QF3.rds
# ERCE_2019_QA6.rds              | # ERCE_2019_QF6.rds

# Base de datos de profesores    | # Base de datos de directores
# ERCE_2019_QP3.rds              | # ERCE_2019_QD3.rds
# ERCE_2019_QP6.rds              | # ERCE_2019_QD6.rds

```

# Codigo 1.2: Inspeccionar los datos


```{r echo=FALSE, out.width = '100%', fig.retina = 1}
knitr::include_graphics('./files/E6IT04.jpg')
```


```{r echo=TRUE, eval=TRUE, messages = FALSE}

# muestra de 10 casos de la variable E6IT04
library(dplyr)
erce::erce_2019_qa6 %>%
dplyr::sample_n(10) %>%
dplyr::select(IDSTUD, IDSCHOOL, COUNTRY, E6IT04) %>%
erce::remove_labels() %>%
tibble::as_tibble()

```


- El segundo problema a resolver, consiste en identificar el **contenido de los datos**.

  - Una base de datos, para ser informativa, requiere de **suplementos** para que podamos producir resultados interpretables.

  - Es decir, para que podamos contestar a una pregunta del tipo "qué proporción de estudiantes habla en el hogar, el mismo lenguaje del test y los cuestionarios", necesitamos saber **qué pregunta** del instrumento recoge información pertinente a esta pregunta.

  - Además requerimos saber como las **respuestas** de las personas fueron **codificadas** en la base de datos.

  - Para estos fines, hay dos fuentes de información relevantes. Una es el **manual de usuario**, el cual contiene un libro de códigos plasmado sobre el cuestionario aplicado.

  - Y por otro lado, podemos recurrir a la **meta-data** de la base de datos, la cual también nos permite acceder a la respuesta que representa cada valor digitado.


```{r echo=TRUE, eval=TRUE}

# mostrar metadata en R
labelled::look_for(erce::erce_2019_qa6)

```

# Codigo 1.3: Variables de diseño

## Variables de diseño

```{r echo=TRUE, eval=TRUE}

# variables de diseño
library(dplyr)
erce::erce_2019_qa6 %>%
dplyr::sample_n(10) %>%
dplyr::select(COUNTRY, STRATA, IDSCHOOL, IDSTUD, WT, WJ, WI) %>%
labelled::lookfor_to_long_format() %>%
tibble::as_tibble()

```

## Muestra de valores de diseño

```{r echo=TRUE, eval=TRUE}

# muestra de valores de variables de diseño
library(dplyr)
erce::erce_2019_qa6 %>%
dplyr::sample_n(10) %>%
dplyr::select(COUNTRY, STRATA, IDSCHOOL, IDSTUD, WT, WJ, WI) %>%
erce::remove_labels() %>%
tibble::as_tibble()

```


- Dependiendo de qué tipo de pregunta o preguntas queramos abordar, necesitamos saber como manejar las **variables de diseño del estudio**.

  - El escenario más sencillo, es cuando queremos trabajar con los datos de un sólo país.

  - Sin embargo, cuando queremos producir resultados empleando más de un país, es posible que sea necesario tratar a las variables de escuelas, estratos, y pesos de diferente forma, para producir resultados para la región.

  - De la misma forma, si queremos producir resultados combinando a la población de estudiantes de Tercer y Sexto grado, debemos tomar decisiones respecto a como tratar a las variables de diseño (e.g., escuelas, estratos, y pesos muestrales).

  - Finalmente, si queremos vincular resultados de TERCE y ERCE, tambien debemos tomar decisiones de qué haremos con las variables de diseño (e.g., escuelas, estratos, y pesos muestrales).


>**Nota**: Los estudios de gran escala permiten realizar comparaciones con datos que empleen un diseño similar, permitiendo comparaciones con otros países, con otros grados, y con datos previos. Pero se requiere realizar algún tratamiento sobre las variables de diseño, de modo que el cálculo de errores, y la expansión de observaciones sea adecuada.


# Codigo 1.4: Dirección de las variables de respuesta


```{r echo=FALSE, out.width = '100%', fig.retina = 1}
knitr::include_graphics('./files/DDIT33.jpg')
```


```{r echo=TRUE, eval=TRUE}

# muestra de valores de variables de diseño
library(dplyr)
erce::erce_2019_qd6 %>%
dplyr::select(DDIT33_07) %>%
labelled::lookfor()

```


- Por convención, **los valores de digitación de respuestas observadas se asignan en secuencias de izquierda a derecha**. De este modo, la primera opción de respuesta se digita como 1, la segunda como 2, y así sucesivamente.

  - Considerando la regla anterior, es posible que, para extraer la información deseada respecto a una pregunta, el usuario secundario requiera **crear variables nuevas** empleando la información original.

  - La variable **DDIT33_07**, nos permite obtener que porcentaje de estudiantes, en un país posee conexión a internet en sus escuelas.

  - Si bien la variable **DDIT33_07** contiene la información de interés, la manera en que estan digitados los valores originales, no necesariamente nos facilita el trabajo para obtener el porcentaje de interés.

  - De este modo, es común que previo a la generación de resultados, los usuarios secundarios requieran **transformar las respuestas digitadas**, a variables que entreguen la información buscada por las preguntas de interés.

>**Nota**: En este ejemplo, una forma de generar resultados consistiría en convertir los valores 2, en valores 0, generando otra variable, y con esta nueva variable calcular los porcentajes esperados.


# Codigo 1.5: Transferibilidad


```{r echo=FALSE, out.width = '100%', fig.retina = 1}
knitr::include_graphics('./files/workflow_2.png')
```


- Es común que la realización de ciertos análisis estadísticos requieran ser realizados en **diferentes software**.

- También es común que los usuarios secundarios **colaboren con otras personas**, y estas otras personas empleen software diferentes a las que se encuentra empleando la primera persona.

- Le llamaremos problema de **transferibilidad**, al escenario en que esté en juego qué tan transferibles son los datos originales a otras plataformas de anáisis de datos.

- Este problema, se resuelve comúnmente, mediante la **exportación de datos** de un software a otro, empleando formatos determinados.

- De este modo, es común que previo a la generación de resultados, los usuarios secundarios requieran **transformar las respuestas digitadas**, a variables que entreguen la información buscada por las preguntas de interés.

- La importacion de datos, la identificación del contenido de los datos, la identificación de las variables de diseño, la preparación de variables, y la exportación de datos, previos a la generación de resultados, son todas etapas que las podemos considerar parte de un **proceso iterativo.** En otras palabras, que lo haremos no solo una vez, sino varias veces.

_A continuación, revisaremos algunos ejemplos de estos procesos, empleando datos de ERCE 2019_.

---


class: middle, inverse

background-image: url(img/background_02.jpeg)
background-size: 100%


.line_space_01[
Problemas y solluciones
]
.line_space_01[
.text_250[
.bold_white[
Abrir datos
]
]
]
.line_space_01[
Problema 1: Cómo cargar los datos de ERCE 2019 en R
]


<br>
<br>

---
background-image: url(img/background_03.jpeg)
background-size: 100%


Problema 1: **Abrir los datos**

.pull_l_50_t_080[

La manera más sencilla de abrir los datos en R, es emplear la librería.

```{r echo = TRUE, eval = FALSE}

#------------------------------------------------
# Abrir los datos desde la librería erce
#------------------------------------------------

erce_a6 <- erce::erce_2019_qa6


```

Otra forma consiste en abrir los datos empleando los archivos `.rds`

```{r echo = TRUE, eval = FALSE}
#------------------------------------------------
# abrir los datos empleando el archivo rds
#------------------------------------------------

data_folder <- '/Users/d/ERCE 2019/'

erce_a6 <- readRDS(paste0(data_folder, 'ERCE_2019_QA6.rds'))

```

En R también es posible abrir los datos en formato STATA `.dta`

```{r echo = TRUE, eval = FALSE}
#------------------------------------------------
# abrir los datos de formato STATA
#------------------------------------------------

data_folder <- '/Users/d/ERCE 2019/'

erce_a6 <- haven::read_dta(paste0(data_folder, 'ERCE_2019_QA6.dta'))

```

Se procede de forma similar para abrir los datos en formato SPSS `.sav`

```{r echo = TRUE, eval = FALSE}
#------------------------------------------------
# abrir los datos de formato SPSS
#------------------------------------------------

data_folder <- '/Users/d/ERCE 2019/'

erce_a6 <- haven::read_sav(paste0(data_folder, 'ERCE_2019_QA6.sav'))

```

]

--

.pull_r_50_t_080[

La primera forma de abrir los datos emplear a la librería `erce` que estamos utilizando en este taller. La ventaja que posee esta forma, es que no necesitamos ubicar donde esta la base de datos, porque se encuentra accesible por el entorno R, a través de las funciones de la librería.
{{content}}
]

--

La segunda forma, requiere que definamos el objeto `data_folder`. Esta es una dirección en sus computadores, donde los archivos de datos se encuentran alojados.
{{content}}

--

La tercera y cuarta forma son equivalentes a la segunda forma. La única diferencia es que se encuentran abriendo los datos en otros formatos, en formatos STATA y SPSS respectivamente.


---
background-image: url(img/background_03.jpeg)
background-size: 100%


Problema 1: **Abrir los datos**

.pull_l_50_t_080[

La manera más sencilla de abrir los datos en R, es emplear la librería.

```{r echo = TRUE, eval = FALSE}

#------------------------------------------------
# Abrir los datos desde la librería erce
#------------------------------------------------

erce_a6 <- erce::erce_2019_qa6


```

Otra forma consiste en abrir los datos empleando los archivos `.rds`

```{r echo = TRUE, eval = FALSE}
#------------------------------------------------
# abrir los datos empleando el archivo rds
#------------------------------------------------

data_folder <- '/Users/d/ERCE 2019/'

erce_a6 <- readRDS(paste0(data_folder, 'ERCE_2019_QA6.rds'))

```

En R también es posible abrir los datos en formato STATA `.dta`

```{r echo = TRUE, eval = FALSE}
#------------------------------------------------
# abrir los datos de formato STATA
#------------------------------------------------

data_folder <- '/Users/d/ERCE 2019/'

erce_a6 <- haven::read_dta(paste0(data_folder, 'ERCE_2019_QA6.dta'))

```

Se procede de forma similar para abrir los datos en formato SPSS `.sav`

```{r echo = TRUE, eval = FALSE}
#------------------------------------------------
# abrir los datos de formato SPSS
#------------------------------------------------

data_folder <- '/Users/d/ERCE 2019/'

erce_a6 <- haven::read_sav(paste0(data_folder, 'ERCE_2019_QA6.sav'))

```

]

--

.pull_r_50_t_080[

Una vez que los datos se encuentran cargados en el entorno R, podemos revisar su contenido.

```{r echo = TRUE, eval = TRUE}

#------------------------------------------------
# abrir datos
#------------------------------------------------

erce_a6 <- erce::erce_2019_qa6

#------------------------------------------------
# revisar su contenido
#------------------------------------------------

library(dplyr)
erce_a6 %>%
dplyr::select(IDSTUD:E6IT10) %>% #<<
dplyr::glimpse()

# Nota: seleccionamos algunas variables, 
#       con la línea `dplyr::select(IDSTUD:E6IT10) %>%`
#       solo para que el output sea visible en pantalla.

```

]


---


class: middle, inverse

background-image: url(img/background_02.jpeg)
background-size: 100%


.line_space_01[
Problemas y soluciones
]
.line_space_01[
.text_250[
.bold_white[
Inspeccionar el contenido de los datos
]
]
]
.line_space_01[
Problema 2: Cómo saber cuál es el contenido de los datos
]


<br>
<br>

---
background-image: url(img/background_03.jpeg)
background-size: 100%


Problema 2: **Inspeccionar el contenido de los datos**

.pull_l_50_t_080[

- Una vez que los datos se encuentran abiertos o cargados, lo siguiente que necesitamos es poder **ver su contenido**.

- Existen **diferentes formas** de inspeccionar los datos en R, una vez que estos se encuentran cargados en la sesión.
{{content}}

]

--

- Una forma global de inspeccionar los datos, es emplear el comando `dplyr::glimpse`. Este nos entrega el listado de variables, su tipo, y una muestra de los valores contenidos en cada columna de la base de datos.


--

.pull_r_50_t_080[


```{r echo = TRUE, eval = TRUE}

#------------------------------------------------
# abrir datos
#------------------------------------------------

erce_a6 <- erce::erce_2019_qa6

#------------------------------------------------
# revisar contenido con dplyr::glimpse()
#------------------------------------------------

library(dplyr)
erce_a6 %>%
dplyr::glimpse()

```

]


---
background-image: url(img/background_03.jpeg)
background-size: 100%


Problema 2: **Inspeccionar el contenido de los datos**

.pull_l_50_t_080[

- Una vez que los datos se encuentran abiertos o cargadaos, lo siguiente que necesitamos es poder **ver su contenido**.

- Existen **diferentes formas** de inspeccionar los datos en R, una vez que estos se encuentran cargados en la sesión.

- Una forma global de inspeccionar los datos, es emplear el comando `dplyr::glimpse`. Este nos entrega el listado de variables, su tipo, y una muestra de los valores contenidos en cada columna de la base de datos.

- Otra forma de inspeccionar los datos, es emplear las funciones de la librería `labelled`. Por ejemplo, empleando el comando `labelled::lookfor` podemos acceder a la meta data de los datos. Una vez aplicado este comando, podemos acceder a la descripción de las variables. Y, para el caso de las variables categóricas, al significado de los valores contenidos en cada columna (e.g., IDCNTRY, COUNTRY).

]


--

.pull_r_50_t_080[


```{r echo = TRUE, eval = TRUE}

#------------------------------------------------
# abrir datos
#------------------------------------------------

erce_a6 <- erce::erce_2019_qa6

#------------------------------------------------
# revisar contenido con labelled::look_for()
#------------------------------------------------

library(dplyr)
erce_a6 %>%
labelled::look_for()

```

]


---
background-image: url(img/background_03.jpeg)
background-size: 100%


Problema 2: **Inspeccionar el contenido de los datos**

.pull_l_50_t_080[

- Una vez que los datos se encuentran abiertos o cargadaos, lo siguiente que necesitamos es poder **ver su contenido**.

- Existen **diferentes formas** de inspeccionar los datos en R, una vez que estos se encuentran cargados en la sesión.


- Una forma global de inspeccionar los datos, es emplear el comando `dplyr::glimpse`. Este nos entrega el listado de variables, su tipo, y una muestra de los valores contenidos en cada columna de la base de datos.

- Otra forma de inspeccionar los datos, es emplear las funciones de la librería `labelled`. Por ejemplo, empleando el comando `labelled::lookfor` podemos acceder a la meta data de los datos. Una vez aplicado este comando, podemos acceder a la descripción de las variables. Y, para el caso de las variables categóricas, al significado de los valores contenidos en cada columna (e.g., IDCNTRY, COUNTRY).

- También es posible generar un libro de códigos con `labelled`, y guardar este libro de códigos en un archivo excel.

]


--

.pull_r_50_t_080[


```{r echo = TRUE, eval = TRUE}

#------------------------------------------------
# abrir datos
#------------------------------------------------

erce_a6 <- erce::erce_2019_qa6

#------------------------------------------------
# guardar libro de codigos
#------------------------------------------------

library(dplyr)
erce_a6 %>%
labelled::lookfor() %>%
labelled::lookfor_to_long_format() %>%
tibble::as_tibble() %>%
openxlsx::write.xlsx('erce_a6_codebook.xlsx', overwrite = TRUE)

```

]


---
background-image: url(img/background_03.jpeg)
background-size: 100%


Problema 2: **Inspeccionar el contenido de los datos**

.pull_l_50_t_080[


- Una vez que los datos se encuentran abiertos o cargadaos, lo siguiente que necesitamos es poder **ver su contenido**.

- Existen **diferentes formas** de inspeccionar los datos en R, una vez que estos se encuentran cargados en la sesión.


- Una forma global de inspeccionar los datos, es emplear el comando `dplyr::glimpse`. Este nos entrega el listado de variables, su tipo, y una muestra de los valores contenidos en cada columna de la base de datos.

- Otra forma de inspeccionar los datos, es emplear las funciones de la librería `labelled`. Por ejemplo, empleando el comando `labelled::lookfor` podemos acceder a la meta data de los datos. Una vez aplicado este comando, podemos acceder a la descripción de las variables. Y, para el caso de las variables categóricas, al significado de los valores contenidos en cada columna (e.g., IDCNTRY, COUNTRY).

- También es posible generar un libro de códigos con `labelled`, y guardar este libro de códigos en un archivo **excel**.

]


.pull_r_50_t_080[


```{r echo=FALSE, out.width = '100%', fig.retina = 1}
knitr::include_graphics('./files/erce_a6_codebook.jpg')
```

]



---


class: middle, inverse

background-image: url(img/background_02.jpeg)
background-size: 100%


.line_space_01[
Problemas y Soluciones
]
.line_space_01[
.text_250[
.bold_white[
Variables de diseño
]
]
]
.line_space_01[
Cuáles son las variables de diseño
]


<br>
<br>

---
background-image: url(img/background_03.jpeg)
background-size: 100%


Problema 3: **Variables de diseño** (cuáles son las variables de diseño)

.pull_l_50_t_080[

- Los estudios de gran escala poseen diferentes **variables de diseño**.

]


--

.pull_r_50_t_080[


```{r echo=TRUE, eval=TRUE, messages = FALSE}

#------------------------------------------------
# abrir datos
#------------------------------------------------

erce_a6 <- erce::erce_2019_qa6

#------------------------------------------------
# muestra de 10 casos de las variables de diseño
#------------------------------------------------

library(dplyr)
erce::erce_2019_qa6 %>%
dplyr::sample_n(10) %>%
dplyr::select(IDCNTRY, IDSCHOOL, IDSTUD, WI, WJ, WT, WS, BRR1, BRR100) %>%
erce::remove_labels() %>%
tibble::as_tibble()

```

]


---
background-image: url(img/background_03.jpeg)
background-size: 100%


Problema 3: **Variables de diseño** (cuáles son las variables de diseño)

.pull_l_50_t_080[

- Los estudios de gran escala poseen diferentes **variables de diseño**.

- Entre las más comunes encontramos a:

  + Las variables de identificación de los **clusters**:
  
      + El identificador de paéses (**IDCNTRY**)

      + El identificador de estratos (**STRATA**)

      + El identificador de escuelas (**IDSCHOOL**)

      + El identificador de estudiantes (**IDSTUD**)

  + Las variables de **pesos** de las observacinoes:

      + Pesos muestrales totales (**WT**)

      + Pesos muestrales escalados (i.e., *senate weights*) (**WS**)

      + Peso de los estudiantes al interior de las escurlas (**WI**)

      + Pesos de las escuelas (**WJ**)

      + Pesos Replicados (**BRR1-BRR100**)

]


--

.pull_r_50_t_080[


```{r echo=TRUE, eval=FALSE, messages = FALSE}

#------------------------------------------------
# abrir datos
#------------------------------------------------

erce_a6 <- erce::erce_2019_qa6

#------------------------------------------------
# definir digitos en consola
#------------------------------------------------

options(digits = 10)
options(scipen = 999999)

#------------------------------------------------
# muestra de 30 casos de las variables de diseño
#------------------------------------------------

library(dplyr)
erce::erce_2019_qa6 %>%
dplyr::sample_n(30) %>%
dplyr::select(IDCNTRY, IDSCHOOL, IDSTUD, WI, WJ, WT, WS, BRR1, BRR100) %>%
erce::remove_labels() %>%
tibble::as_tibble() %>%
knitr::kable(., digits = 2)


```

```text

| IDCNTRY| IDSCHOOL|   IDSTUD|  WI|    WJ|     WT|   WS|   BRR1| BRR100|
|-------:|--------:|--------:|---:|-----:|------:|----:|------:|------:|
|     214|     1158| 11580516| 5.8|   6.5|   38.0| 0.24|   19.0|   57.0|
|     591|     1139| 11390123| 1.1|   7.0|    7.5| 0.11|    3.7|    3.7|
|      76|     1144| 11440113| 3.9| 115.1|  452.3| 0.14|  678.4|  678.4|
|     340|     1146| 11460121| 1.4|   4.2|    5.8| 0.03|    2.9|    2.9|
|     604|     1033| 10330218| 2.1|  31.3|   65.0| 0.12|   97.6|   32.5|
|     604|     1160| 11600314| 3.2|  25.4|   81.5| 0.15|  122.3|   40.8|
|     340|     1081| 10810204| 2.2|  28.2|   62.8| 0.34|   94.2|   31.4|
|      32|     1048| 10480303| 3.5|  62.9|  220.2| 0.27|  110.1|  110.1|
|     340|     1131| 11310301| 3.3|  13.0|   43.4| 0.23|   65.2|   65.2|
|     192|     1096| 10960117| 2.1|   8.7|   17.9| 0.18|   26.9|    8.9|
|     170|     1136| 11360112| 1.1| 192.6|  218.2| 0.26|  327.3|  327.3|
|     558|     1170| 11700440| 4.7|   1.8|    8.4| 0.14|    4.2|   12.6|
|     600|     1121| 11210114| 1.2|  14.3|   17.7| 0.17|    8.8|   26.6|
|     484|     1218| 12180101| 2.3| 466.7| 1066.7| 0.47| 1600.1|  533.4|
|     320|     1001| 10010115| 1.1|  65.1|   72.4| 0.24|   36.2|  108.5|
|      76|     1004| 10040233| 3.2| 135.8|  431.5| 0.14|  647.2|  647.2|
|     214|     1143| 11430123| 5.0|   5.9|   29.5| 0.19|   44.2|   14.7|
|     558|     1230| 12300231| 3.1|   2.7|    8.4| 0.14|    4.2|   12.6|
|     170|     1110| 11100214| 2.4|  80.8|  197.6| 0.23|   98.8|  296.4|
|     604|     1283| 12830307| 4.0|  20.5|   81.9| 0.15|   41.0|   41.0|
|     484|     1204| 12040215| 2.1| 188.1|  389.2| 0.17|  194.6|  194.6|
|     218|     1073| 10730204| 3.0|  13.1|   39.4| 0.13|   19.7|   59.1|
|     600|     1181| 11810102| 1.0|  50.1|   51.8| 0.49|   77.7|   25.9|
|     170|     1151| 11510210| 4.0|  35.9|  143.7| 0.17|  215.6|   71.9|
|     170|     1004| 10040145| 3.4|  38.8|  130.6| 0.15|  195.9|   65.3|
|      76|     1035| 10350218| 3.7| 164.5|  603.3| 0.19|  905.0|  905.0|
|     484|     1011| 10110113| 2.2| 153.6|  343.3| 0.15|  515.0|  515.0|
|     604|     1130| 11300216| 5.2|  10.6|   54.5| 0.10|   81.8|   27.2|
|     591|     1271| 12710114| 2.1|   7.2|   15.2| 0.23|    7.6|   22.9|
|     591|     1163| 11630503| 5.0|   2.8|   14.2| 0.21|   21.2|   21.2|

```


]

---


class: middle, inverse

background-image: url(img/background_02.jpeg)
background-size: 100%


.line_space_01[
Problemas y soluciones
]
.line_space_01[
.text_250[
.bold_white[
Variables de diseño
]
]
]
.line_space_01[
Problema 3: Qué hacer con las variables de diseño, para obtener resultados de la región
]


<br>
<br>

---
background-image: url(img/background_03.jpeg)
background-size: 100%


Problema 3: **Variables de diseño** (cómo producir resultados para la región)


.pull_l_50_t_080[

- Los **pesos muestrales**, en particular el peso total de las observaciones (**WT**) expande las observaciones al total esperado de la población de interés.

  - Si empleáramos este peso, para tratar de reproducir los resultados regionales sobre los niveles de lectura, nuestro **estimado estaría distorsionado.**

  - Los porcentajes de nivel de lectura, estarían siendo calculados **empleando el total esperado** de la población de cada país. Lo anterior, tiene como consecuencia que, países más grandes como Brasil y Mexico, contribuyen con más observaciones esperadas, en contraste a países con una población de estudiantes de menor tamaño como Uruguay, y Colombia.

- Para garantizar que cada uno de los países contribuya de forma equivalente, requerimos emplear el peso escalado (**WS**). Este peso, suma a un total de mil observaciones de cada país.

- **En resumen**, cuando queremos calcular resultados que involucran más de un país, necesitamos elegir o crear un peso muestral que sea adecuado a nuestros propósitos. En este caso, **WS** cumple este requisito.

]


--

.pull_r_50_t_080[

```{r echo=FALSE, out.width = '100%', fig.retina = 1}
knitr::include_graphics('./files/erce_a6_nivel_lectura.jpg')
```


]


---
background-image: url(img/background_03.jpeg)
background-size: 100%


Problema 3: **Variables de diseño** (cómo producir resultados para la región)

.pull_l_50_t_080[

- Un segundo aspecto a considerar son los **identificadores de clusters** (e.g., escuelas, estratos y países).

  - Es muy común que las variables de diseño **no sean únicas** entre las bases de datos de paises, en los estudios de gran escala. Esto quiere decir que, por ejemplo la escuela **1001** se repite entre todos los países participantes.

  - La repetición de los clusters como los identificadores de escuelas, pueden hacerle creer a los software de turno que **los estudiantes de la escuela 1001 de Colombia, estan en la misma escuela 1001 de Ecuador**, y no queremos cometer este tipo de errores.

  - De este modo, si quisiéramos implementar un metodo de corrección de calculo de errores como **Taylor Series Linearization**, necesitaremos crear identificadores de cluster que sean únicos entre países.

  - De manera que el software que calcule los resultados no solo corrija el punto estimado de forma adecuada empleando el peso pertinente (**WS**), sino que además considere cómo estan anidados las observaciones entre las escuelas, y los estratos de cada país, para obtener tamaños de error razonables.

- **En resumen**, además de elegir o crear pesos adecuados para nuestros propósitos, necesitamos **identificadores de cluster** que sean únicos entre países para este caso.


]

--

.pull_r_50_t_100[

```{r echo=TRUE, eval=FALSE, messages = FALSE}

#------------------------------------------------
# abrir datos
#------------------------------------------------

erce_a6 <- erce::erce_2019_qa6

#------------------------------------------------
# la escuela 1001 se repite entre todos los países
#------------------------------------------------

library(dplyr)
erce_a6 %>%
erce::remove_labels() %>%
dplyr::select(COUNTRY, IDSCHOOL) %>%
unique() %>%
dplyr::filter(IDSCHOOL == 1001) %>%
dplyr::count(COUNTRY, IDSCHOOL) %>%
knitr::kable(., digits = 2)


```

```text

|COUNTRY | IDSCHOOL|  n|
|:-------|--------:|--:|
|ARG     |     1001|  1|
|BRA     |     1001|  1|
|COL     |     1001|  1|
|CRI     |     1001|  1|
|CUB     |     1001|  1|
|DOM     |     1001|  1|
|ECU     |     1001|  1|
|GTM     |     1001|  1|
|MEX     |     1001|  1|
|NIC     |     1001|  1|
|PAN     |     1001|  1|
|PER     |     1001|  1|
|PRY     |     1001|  1|
|SLV     |     1001|  1|
|URY     |     1001|  1|

```

]

---


class: middle, inverse

background-image: url(img/background_02.jpeg)
background-size: 100%


.line_space_01[
Problemas y soluciones
]
.line_space_01[
.text_250[
.bold_white[
Generación de resultados para la región
]
]
]
.line_space_01[
Problema 3: Secuencia de códigos para producir un resultado regional

]


<br>
<br>

---
background-image: url(img/background_03.jpeg)
background-size: 100%


Problema 3: **Variables de diseño** (cómo producir resultados para la región)


.pull_l_50[

```{r echo = TRUE, eval = TRUE}

# -------------------------------------------------------------------
# nivel de lectura en la region
# -------------------------------------------------------------------

#------------------------------------------------
# cluster únicos
#------------------------------------------------

data_lan <- erce::erce_2019_qa6 %>%
erce::remove_labels() %>%
mutate(id_s = as.numeric(as.factor(paste0(IDCNTRY, "_", STRATA)))) %>%
mutate(id_j = as.numeric(as.factor(paste0(IDCNTRY, "_", IDSCHOOL)))) %>%
mutate(id_i = seq(1:nrow(.)))


#------------------------------------------------
# variable dummy para los niveles esperados
#------------------------------------------------

data_lan <- data_lan %>%
mutate(all = 1) %>%
mutate(lan_min_1 = case_when(
LAN_L1 == 'I'   ~ 0,
LAN_L1 == 'II'  ~ 0,
LAN_L1 == 'III' ~ 1,
LAN_L1 == 'IV'  ~ 1)) %>%
mutate(lan_min_2 = case_when(
LAN_L2 == 'I'   ~ 0,
LAN_L2 == 'II'  ~ 0,
LAN_L2 == 'III' ~ 1,
LAN_L2 == 'IV'  ~ 1)) %>%
mutate(lan_min_3 = case_when(
LAN_L3 == 'I'   ~ 0,
LAN_L3 == 'II'  ~ 0,
LAN_L3 == 'III' ~ 1,
LAN_L3 == 'IV'  ~ 1)) %>%
mutate(lan_min_4 = case_when(
LAN_L4 == 'I'   ~ 0,
LAN_L4 == 'II'  ~ 0,
LAN_L4 == 'III' ~ 1,
LAN_L4 == 'IV'  ~ 1)) %>%
mutate(lan_min_5 = case_when(
LAN_L5 == 'I'   ~ 0,
LAN_L5 == 'II'  ~ 0,
LAN_L5 == 'III' ~ 1,
LAN_L5 == 'IV'  ~ 1))

```

]

--

.pull_r_50_t_090[

- Una forma general de llamar a las variables de clustering, es llamarlas id_i, id_j, id_s, y id_k
{{content}}

]

--

```text

# variables de clustering

id_i = indentificador único de estudiantes
id_j = indentificador único de escuelas (i.e., primary sampling unit)
id_s = indentificador único de estratos
id_k = indentificador único de países

```
{{content}}

--

- Otro detalle a considerar, es que muchas de las librerías que nos permiten realizar estimaciones a la población, esperan bases de datos sin meta-data. De caso contrario, no reconocen a la base de datos como analizable, y no pueden realizar cálculos. De este modo, en este ejemplo empleamos la función `erce::remove_labels()` para que `library(survey)` no nos genere problemas.
{{content}}

--

- Además, necesitamos tener una variable **dummy** que identifique a todos los estudiantes que se encuentren sobre el nivel esperado, es decir al menos sobre el nivel III de lectura.
{{content}}

--

- Como los niveles de desempeño sobre lectura, provienen de los valores plausibles, entonces necesitamos generar 5 variables de este tipo.


---
background-image: url(img/background_03.jpeg)
background-size: 100%


Problema 3: **Variables de diseño** (cómo producir resultados para la región)


.pull_l_50_t_060[

```{r echo=TRUE, eval = TRUE}

# -------------------------------------------------------------------
# nivel de lectura en la region
# -------------------------------------------------------------------

# [... continua código anterior]

#------------------------------------------------
# base de datos con diseño
#------------------------------------------------

# survey method: taylor series linearization
data_tsl  <- survey::svydesign(
             data    = data_lan, 
             weights = ~WS,
             strata  = ~id_s,
             id = ~id_j,
             nest = TRUE)


# Opción: corección a unidad primaria de muestreo que resulte 
# única al estrato

library(survey)
options(survey.lonely.psu="adjust")


```

]

--

.pull_r_50_t_090[

- Primero creamos el objeto **data_tsl**. Este objeto es nuestra base de datos con argumentos necesarios para que la librería **survey** pueda entregarnos estimaciones a la poblacón.
{{content}}

]



--

- En esta primera sección del código, estamos indicando el peso que necesitamos emplear (**WS**), además de las variables de cluster que generamos anteriormente (**id_j**, **id_s**).
{{content}}

--

- Además, necesitamos una función que nos permita combinar los estimados de diferentes **valores plausibles** (Rutkowski et al., 2010). En este caso, estamos empleando una función generada por Thomas Lumley, autor de la librería **survey** (Lumley, 2010), la cual nos permite calcular resultados para cada valor plausible, sin la necesidad de que tengamos que crear una lista de bases de datos.
{{content}}

--

- En la siguiente lámina, vamos a aplicar esta funcion **withPV()**, la cual facilitará el proceso de generación de resultados.


---
background-image: url(img/background_03.jpeg)
background-size: 100%


Problema 3: **Variables de diseño** (cómo producir resultados para la región)



.pull_l_50_t_100[

```{r echo=TRUE, eval = FALSE}

# -------------------------------------------------------------------
# nivel de lectura en la region
# -------------------------------------------------------------------

# [... continua código anterior]

#------------------------------------------------
# nivel de lectura esperado
#------------------------------------------------

results <- mitools::withPV(
   mapping = lan_min ~ lan_min_1 + lan_min_2 + lan_min_3 + lan_min_4 + lan_min_5,
   data = data_tsl,
   action=quote(survey::svymean(~lan_min, design=data_tsl)),
   rewrite = TRUE
   )

#------------------------------------------------
# obtener resultados
#------------------------------------------------

summary(mitools::MIcombine(results))


```

```text

summary(mitools::MIcombine(results))
Multiple imputation results:
      function(mapping, design, action, ...) UseMethod("withPV",design)
      MIcombine.default(results)
             results             se       (lower       upper) missInfo
lan_min 0.3118589523 0.003815336074 0.3041889541 0.3195289505     32 %

```

]

--

.pull_r_50_t_090[

- En la primera sección de este código, estamos aplicando la función **withPV**. En esta función, empleando un esquema de fórmulas, podemos llamar a nuestra variable combinada como quisiéramos. En este caso, la estamos llamando **lan_min**.
{{content}}

]



--

- Lo importante en la definición de **lan_min**, es que incluyamos los valores plausibles que necesitamos. En este caso, nuestro argumento crítico es:

```

lan_min ~ lan_min_1 + lan_min_2 + lan_min_3 + lan_min_4 + lan_min_5,

```


{{content}}

--

- En `design = ` necesitamos incluir nuestro objeto de diseño, en este caso **data_tsl**. Y respectivamente, necesitamos proceder de igual forma dentro del argumento `action = `
{{content}}

--

- La aplicación de la función **withPV** entrega una lista de resultados. Esta lista de resultados, necesitamos combinarla empleando las reglas de Rubin (Schafer, 1997). Para estos fines, empleamos la función `mitools::MIcombine(results)` al interior de la función `summary()` de modo de obtener puntos estimados, error del punto estimado e intervalos de confianza.
{{content}}

---
background-image: url(img/background_03.jpeg)
background-size: 100%


Problema 3: **Variables de diseño** (cómo producir resultados para la región)



.pull_l_50_t_100[

```{r echo=TRUE, eval = FALSE}

# -------------------------------------------------------------------
# nivel de lectura en la region
# -------------------------------------------------------------------

# [... continua código anterior]

#------------------------------------------------
# tabla de medias
#------------------------------------------------

estimados <- summary(mitools::MIcombine(results))

table_read <- estimados %>%
               tibble::rownames_to_column("lan_min") %>%
               rename(
                lan = results, 
                lan_se = se,
                ll = 4,
                ul = 5,
                miss = 6
                ) %>%
               mutate(lan = lan*100) %>%
               mutate(lan_se = lan_se*100) %>%
               mutate(ll = ll*100) %>%
               mutate(ul = ul*100)

# -----------------------------------------------
# mostrar tabla
# -----------------------------------------------

options(digits=10)
options(scipen = 999999)

knitr::kable(table_read, digits = 1)


```


```text

|lan_min |  lan| lan_se|   ll| ul|miss |
|:-------|----:|------:|----:|--:|:----|
|lan_min | 31.2|    0.4| 30.4| 32|32 % |

```

]

--

.pull_r_50_t_090[


- Finalmente, podemos manipular los resultados obtenidos para generar tabla que sea más amigable de leer. Con todo lo anterior, vemos que podemos reproducir los resultados reportados en la serie `#ponlelupa`, y lo que aparece en el informe ejecutivo.

```{r echo=FALSE, out.width = '100%', fig.retina = 1}
knitr::include_graphics('./files/erce_a6_nivel_lectura_ejecutivo.jpg')
```

]

---


class: middle, inverse

background-image: url(img/background_02.jpeg)
background-size: 100%


.line_space_01[
Problemas y Soluciones
]
.line_space_01[
.text_250[
.bold_white[
Generación de resultados para la región
]
]
]
.line_space_01[
Resumen de todos los pasos realizados para generar un resultado regional
]


<br>
<br>

---
background-image: url(img/background_03.jpeg)
background-size: 100%

**Generación de resultados para la región** como desarollo

.pull_l_50_t_100[

```{r echo=FALSE, out.width = '100%', fig.retina = 1}
knitr::include_graphics('./files/erce_a6_nivel_lectura_ejecutivo.jpg')
```

```text

# Resultados generados empleando library(survey) y withPV()

|lan_min |  lan| lan_se|   ll| ul|miss |
|:-------|----:|------:|----:|--:|:----|
|lan_min | 31.2|    0.4| 30.4| 32|32 % |

```

Realizamos una **series de pasos** para poder reproducir la cifra 31.2%, la que nos indica la proporción de estudiantes que alcanza el nivel esperado de competencia de lectura en la región. A la derecha de esta lámina, incluimos un listado de los pasos realizados.


]

--

.pull_r_50_t_090[

- Abrir los datos (**erce::erce_2019_qa6**)

- Remover la meta data de los datos (**erce::remove_labels**)

- La creación de variables clustering que fueran únicas entre paises (e.g., **id_i**, **id_j**, **id_s**).

- La creación de variables dummy sobre los niveles de desempeño (e.g., **lan_min_1**, **lan_min_2**, **lan_min_3**, **lan_min_4**, **lan_min_5**).

- La definición de un objeto, que incluya la información del diseño (i.e., **data_tsl**).

- Empleamos a una función que nos permitiera estimar los resultados para cada valor plausible (**withPV**).

- Combinamos los resultados generados, empleando funciones diseñadas para trabajar con imputaciones (**mitools::MIcombine(results)**).

- Finalmente, **definimos la forma en que se presentan los resultados** en consola, para que esta empleara la misma cantidad de digitos presentes en el informe ejecutivo, y en el reporte de `#ponlelupa`.


]


---


class: middle, inverse

background-image: url(img/background_02.jpeg)
background-size: 100%


.line_space_01[
Problemas y Soluciones
]
.line_space_01[
.text_250[
.bold_white[
Transferibilidad y Reproducibilidad
]
]
]
.line_space_01[
Cómo entregar los resultados generados, y como repetir este ejercicio.
]


<br>
<br>

---
background-image: url(img/background_03.jpeg)
background-size: 100%

**Transferibilidad y Reproducibilidad**


.pull_l_50_t_100[

```{r echo=FALSE, out.width = '100%', fig.retina = 1}
knitr::include_graphics('./files/workflow_2.png')
```

]

--

.pull_r_50_t_080[

- Para completar el ciclo de **análisis como desarollo**, tenemos que abordar dos aspectos: la capacidad de **transferir** los resultados generados, y la capacidad de poder **repetir** el proceso.
{{content}}

]

--

- El primer aspecto refiere a la **transferibilidad**. Incluiremos como un problema de transferibilidad a la generación de resultados. Para que un resultado generado sea transferible, necesitamos poder **compartir** el resultado con otros usuarios, de alguna manera.
{{content}}

--

- Una forma de **compartir** el resultado generado, es producir una **tabla en excel**. Esta opción permite que muchos más usuarios tengan acceso a los resultados que hemos producido; y no solo entre usuarios de **R**.


```{r echo = FALSE, eval = TRUE, messages = FALSE}

# -------------------------------------------------------------------
# nivel de lectura en la region
# -------------------------------------------------------------------

#------------------------------------------------
# nivel de lectura esperado
#------------------------------------------------

results <- mitools::withPV(
   mapping = lan_min ~ lan_min_1 + lan_min_2 + lan_min_3 + lan_min_4 + lan_min_5,
   data = data_tsl,
   action = quote(survey::svymean( ~lan_min, data_tsl))
  )

#------------------------------------------------
# tabla de medias
#------------------------------------------------

estimados <- summary(mitools::MIcombine(results))

table_read <- estimados %>%
               tibble::rownames_to_column("lan_min") %>%
               rename(
                lan = results, 
                lan_se = se,
                ll = 4,
                ul = 5,
                miss = 6
                ) %>%
               mutate(lan = lan*100) %>%
               mutate(lan_se = lan_se*100) %>%
               mutate(ll = ll*100) %>%
               mutate(ul = ul*100)


```

```{r echo = TRUE, eval = TRUE}

# -------------------------------------------------------------------
# nivel de lectura en la region
# -------------------------------------------------------------------

#------------------------------------------------
# exportar resultados
#------------------------------------------------

table_read %>%
openxlsx::write.xlsx(., 
  'tabla_porcentaje_nivel_lectura.xlsx',
  overwrite = TRUE)

```

{{content}}


---
background-image: url(img/background_03.jpeg)
background-size: 100%

**Transferibilidad** y Reproducibilidad


.pull_l_50_t_100[

```{r echo=FALSE, out.width = '100%', fig.retina = 1}
knitr::include_graphics('./files/tabla_porcentaje_nivel_lectura.jpg')
```

]


.pull_r_50_t_080[

- Para completar el ciclo de **análisis como desarollo**, tenemos que abordar dos aspectos: la capacidad de **transferir** los resultados generados, y la capacidad de poder **repetir** el proceso.


- El primer aspecto refiere a la **transferibilidad**. Incluiremos como un problema de transferibilidad a la generación de resultados. Para que un resultado generado sea transferible, necesitamos poder **compartir** el resultado con otros usuarios, de alguna manera.



- Una forma de **compartir** el resultado generado, es producir una **tabla en excel**. Esta opción permite que muchos más usuarios tengan acceso a los resultados que hemos producido; y no solo entre usuarios de **R**.



```{r echo = TRUE, eval = TRUE}

# -------------------------------------------------------------------
# nivel de lectura en la region
# -------------------------------------------------------------------

#------------------------------------------------
# exportar resultados
#------------------------------------------------

table_read %>%
openxlsx::write.xlsx(., 
  'tabla_porcentaje_nivel_lectura.xlsx',
  overwrite = TRUE)

```

]


---
background-image: url(img/background_03.jpeg)
background-size: 100%

Transferibilidad y **Reproducibilidad**


.pull_l_50_t_100[

```{r echo=FALSE, out.width = '100%', fig.retina = 1}
knitr::include_graphics('./files/reproducible_problem_3.jpg')
```

.text_80[

>**Nota**: imagen de como se un código reproducible (Xie, 2013), en formato **RMarkdown**. A la izquierda se encuentra el código escrito en Sublime Text, mientras que a la derecha se encuentra un *screenshot* de la terminal de **R** mostrando los logs de la ejecución exitosa del código.

Este código lo pueden bajar desde el siguiente link:

```text

https://github.com/dacarras/erce_2022_lsa/blob/main/ejemplo_problema_3_resultado_regional.rmd

```

  ]
]


.pull_r_50_t_080[

- Finalmente, todos los pasos revisados hasta ahora, los podemos juntar en un solo **código**. 

- Desde la apertura de los datos, la creación de variables de clustering, la creación de variables, la estimación de resultados con valores plausibles, la combinación de las estimaciones realizadas, y la definición de la forma de presentación de resultados, la podemos agrupar en un mismo documento **accionable**.


]


---

background-image: url(img/background_03.jpeg)
background-size: 100%

Transferibilidad y **Reproducibilidad**


.pull_l_50_t_100[

```{r echo=FALSE, out.width = '100%', fig.retina = 1}
knitr::include_graphics('./files/reproducible_problem_3_html.jpg')
```

.text_80[

>**Nota**: imagen del output html generado con el código escrito en **RMarkdown**.
  ]
]


.pull_r_50_t_080[

- Finalmente, todos los pasos revisados hasta ahora, los podemos juntar en un solo **código**. 

- Desde la apertura de los datos, la creación de variables de clustering, la creación de variables, la estimación de resultados con valores plausibles, la combinación de las estimaciones realizadas, y la definición de la forma de presentación de resultados, la podemos agrupar en un mismo documento **accionable**.

- Una ventaja de implementar esta forma de trabajo, es que el código generado, no solo nos entrega la tabla de resultados en excel, la cual es **transferible**. Sino que además, el código escrito que produce los resultados es **reproducible**. Es decir, que nos permite generar los resultados nuevamente, y plasma los resultados encontrados en esta tarea.

]


---

background-image: url(img/background_03.jpeg)
background-size: 100%

Transferibilidad y **Reproducibilidad**


.pull_l_50_t_100[

```{r echo=FALSE, out.width = '100%', fig.retina = 1}
knitr::include_graphics('./files/reproducible_problem_3_html.jpg')
```

.text_80[

>**Nota**: imagen del output html generado con el código escrito en **RMarkdown**.
  ]
]


.pull_r_50_t_080[

- Finalmente, todos los pasos revisados hasta ahora, los podemos juntar en un solo **código**. 

- Desde la apertura de los datos, la creación de variables de clustering, la creación de variables, la estimación de resultados con valores plausibles, la combinación de las estimaciones realizadas, y la definición de la forma de presentación de resultados, la podemos agrupar en un mismo documento **accionable**.

- Una ventaja de implementar esta forma de trabajo, es que el código generado, no solo nos entrega la tabla de resultados en excel, la cual es **transferible**. Sino que además, el código escrito que produce los resultados es **reproducible**. Es decir, que nos permite generar los resultados nuevamente, y plasma los resultados encontrados en esta tarea.

- Este tipo de código facilita que **reutilicemos** el código empleado, para resolver problemas similares. Y además implementa el proceso **iterativo**. Es decir, que podemos repetir la secuencia de pasos hasta llegar al producto final, incorporando mejoras en cada iteración.


]


---

background-image: url(img/background_03.jpeg)
background-size: 100%

Transferibilidad y **Reproducibilidad**


.pull_l_50_t_100[

```{r echo=FALSE, out.width = '100%', fig.retina = 1}
knitr::include_graphics('./files/reproducible_problem_3_html.jpg')
```

.text_80[

>**Nota**: imagen del output html generado con el código escrito en **RMarkdown**.
  ]
]


.pull_r_50_t_080[

- Finalmente, todos los pasos revisados hasta ahora, los podemos juntar en un solo **código**. 

- Desde la apertura de los datos, la creación de variables de clustering, la creación de variables, la estimación de resultados con valores plausibles, la combinación de las estimaciones realizadas, y la definición de la forma de presentación de resultados, la podemos agrupar en un mismo documento **accionable**.

- Una ventaja de implementar esta forma de trabajo, es que el código generado, no solo nos entrega la tabla de resultados en excel, la cual es **transferible**. Sino que además, el código escrito que produce los resultados es **reproducible**. Es decir, que nos permite generar los resultados nuevamente, y plasma los resultados encontrados en esta tarea.

- Este tipo de código facilita que **reutilicemos** el código empleado, para resolver problemas similares. Y además implementa el proceso **iterativo**. Es decir, que podemos repetir el proceso de de secuencia de pasos, hasta llegar al producto final, incorporando mejoras en cada iteración.

- En este taller, invitamos a los presentes a probar esta forma de trabajo, y esperamos que resulte ventajoso para la **produción de resultados como desarollo**.

]


---





class: inverse split-two


background-image: url(img/background_02.jpeg)
background-size: 100%


.column[
.pull_l_50_1[

.text_180[
.bold_white[
<br>
Muchas gracias!
    ]
  ]
]

.pull_l_50_2[
.line_space_03[
.text_60[

*Carrasco, D., PhD*

*Centro de Medición MIDE UC,*

*Pontificia Universidad Católica de Chile*

https://dacarras.github.io/
    ]
    ]
  ]
]








.column[

.text_180[
.bold_white[
<br>
Referencias
  ]
]

.text_100[
.french[

Lumley, T. (2010). Complex Surveys: A Guide to Analysis Using R. Wiley.

Parker, H. (2017). Opinionated analysis development (pp. 1–13). https://doi.org/10.7287/peerj.preprints.3210

Rutkowski, L., Gonzalez, E., Joncas, M., & von Davier, M. (2010). International Large-Scale Assessment Data: Issues in Secondary Analysis and Reporting. Educational Researcher, 39(2), 142–151. https://doi.org/10.3102/0013189X10363170

Schafer, J. L. (1997). Analysis of Incomplete Multivariate Data. In We (Vol. 141, Issue 7). Chapman & Hall/CRC.

Xie, Y. (2013). Dynamic Documents with R and knitr. In Dynamic Documents with R and knitr. Chapman and Hall/CRC. http://www.crcpress.com/product/isbn/9781482203530



  ] 
 ]
]








